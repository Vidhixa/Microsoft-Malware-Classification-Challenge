

import java.io.BufferedReader;
import java.io.File;
import java.io.FileInputStream;
import java.io.FileReader;
import java.io.IOException;
import java.io.InputStream;
import java.io.InputStreamReader;
import java.io.Writer;
import java.math.BigInteger;
import java.sql.SQLException;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.regex.Matcher;
import java.util.regex.Pattern;

import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.analysis.TokenStream;
import org.apache.lucene.analysis.core.KeywordAnalyzer;
import org.apache.lucene.analysis.core.SimpleAnalyzer;
import org.apache.lucene.analysis.miscellaneous.PerFieldAnalyzerWrapper;
import org.apache.lucene.analysis.standard.StandardAnalyzer;
import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
import org.apache.lucene.document.Document;
import org.apache.lucene.document.Field;
import org.apache.lucene.document.Field.Store;
import org.apache.lucene.document.StringField;
import org.apache.lucene.document.TextField;
import org.apache.lucene.index.DirectoryReader;
import org.apache.lucene.index.Fields;
import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.IndexWriter;
import org.apache.lucene.index.IndexWriterConfig;
import org.apache.lucene.index.IndexWriterConfig.OpenMode;
import org.apache.lucene.index.IndexableField;
import org.apache.lucene.index.MultiFields;
import org.apache.lucene.index.Term;
import org.apache.lucene.index.TermsEnum;
import org.apache.lucene.index.Terms;
import org.apache.lucene.index.CheckIndex.Status.TermIndexStatus;
import org.apache.lucene.queryparser.classic.ParseException;
import org.apache.lucene.queryparser.classic.QueryParser;
import org.apache.lucene.search.IndexSearcher;
import org.apache.lucene.search.Query;
import org.apache.lucene.search.TermQuery;
import org.apache.lucene.search.TopDocs;
import org.apache.lucene.store.Directory;
import org.apache.lucene.store.FSDirectory;
import org.apache.lucene.store.IOContext;
import org.apache.lucene.store.RAMDirectory;
import org.apache.lucene.util.Version;


public class PreProDifferenceASM {
	
	
	static int count = 0;
	
	public static void makeMap(Map<String, Boolean> instruction)
	{
			
		instruction.put("aaa",true);
		instruction.put("aad",true);
		instruction.put("aam",true);
		instruction.put("aas",true);
		instruction.put("adc",true);
		instruction.put("add",true);
		instruction.put("and",true);
		instruction.put("call",true);
		instruction.put("cbw",true);
		instruction.put("clc",true);
		instruction.put("cld",true);
		instruction.put("cli",true);
		instruction.put("cmc",true);
		instruction.put("cmp",true);
		instruction.put("cmpsb",true);
		instruction.put("cmpsw",true);
		instruction.put("cwd",true);
		instruction.put("daa",true);
		instruction.put("das",true);
		instruction.put("dec",true);
		instruction.put("div",true);
		instruction.put("esc",true);
		instruction.put("hlt",true);
		instruction.put("idiv",true);
		instruction.put("imul",true);
		instruction.put("in",true);
		instruction.put("inc",true);
		instruction.put("int",true);
		instruction.put("into",true);
		instruction.put("iret",true);
		instruction.put("jcc",true);
		instruction.put("jcxz",true);
		instruction.put("jmp",true);
		instruction.put("lahf",true);
		instruction.put("lea",true);
		instruction.put("les",true);
		instruction.put("lock",true);
		instruction.put("lodsb",true);
		instruction.put("lodsb",true);
		instruction.put("loop",true);
		instruction.put("mov",true);
		instruction.put("movsb",true);
		instruction.put("movsw",true);
		instruction.put("mul",true);
		instruction.put("neg",true);
		instruction.put("nop",true);
		instruction.put("not",true);
		instruction.put("or",true);
		instruction.put("out",true);
		instruction.put("pop",true);
		instruction.put("popf",true);
		instruction.put("push",true);
		instruction.put("pushf",true);
		instruction.put("rcl",true);
		instruction.put("rcr",true);
		instruction.put("ret",true);
		instruction.put("retn",true);
		instruction.put("retl",true);
		instruction.put("rol",true);
		instruction.put("ror",true);
		instruction.put("sahf",true);
		instruction.put("sal",true);
		instruction.put("sar",true);
		instruction.put("sbb",true);
		instruction.put("scasb",true);
		instruction.put("scasw",true);
		instruction.put("shl",true);
		instruction.put("shr",true);
		instruction.put("stc",true);
		instruction.put("std",true);
		instruction.put("sti",true);
		instruction.put("stosb",true);
		instruction.put("stosw",true);
		instruction.put("sub",true);
		instruction.put("test",true);
		instruction.put("wait",true);
		instruction.put("xchg",true);
		instruction.put("xlat",true);
		instruction.put("xor",true);
		
		instruction.put("bound",true);
		instruction.put("ins",true);
		instruction.put("enter",true);
		instruction.put("leave",true);
		instruction.put("outs",true);
		instruction.put("popa",true);
		
		instruction.put("arpl",true);
		instruction.put("clts",true);
		instruction.put("lar",true);
		instruction.put("lgdt",true);
		instruction.put("lidt",true);
		instruction.put("lldt",true);
		instruction.put("lmsw",true);
		instruction.put("loadall",true);
		instruction.put("lsl",true);
		instruction.put("ltr",true);
		instruction.put("sgdt",true);
		instruction.put("sidt",true);
		instruction.put("sldt",true);
		instruction.put("smsw",true);
		instruction.put("str",true);
		instruction.put("verr",true);
		instruction.put("verw",true);
		
		instruction.put("bsf",true);
		instruction.put("bsr",true);
		instruction.put("bt",true);
		instruction.put("btc",true);
		instruction.put("btr",true);
		instruction.put("bts",true);
		instruction.put("cdq",true);
		instruction.put("cmpsd",true);
		instruction.put("cwde",true);
		instruction.put("insd",true);
		instruction.put("jecxz",true);
		instruction.put("lfs",true);
		instruction.put("lgs",true);
		instruction.put("lss",true);
		instruction.put("lodsd",true);
		instruction.put("movsd",true);
		instruction.put("movsx",true);
		instruction.put("movzx",true);
		instruction.put("outsd",true);
		instruction.put("popad",true);
		instruction.put("popfd",true);
		instruction.put("pushad",true);
		instruction.put("pushfd",true);
		instruction.put("lodsd",true);
		instruction.put("scasd",true);
		instruction.put("setcc",true);
		instruction.put("shld",true);
		instruction.put("shrd",true);
		instruction.put("stosd",true);
		
		instruction.put("jnz",true);
		instruction.put("jb",true);
		instruction.put("ja",true);
		instruction.put("jbe",true);
	}
	
	
	public static void getTrainlabels(HashMap<String,Integer> trainLabel) throws IOException
	{
		String path = "/home/vbox/train/trainLabels.csv";
		File file = new File(path);
		FileReader fileReader = new FileReader(file);
		BufferedReader reader = new BufferedReader(fileReader);
	    String line = null;
	    line = reader.readLine();//for firstline
	    while((line = reader.readLine()) != null ) 
	    {
	    	String[] words = line.split(",");
	    	assert(words.length == 2);
	    	trainLabel.put(words[0], Integer.parseInt(words[1]));
	    }
	}
	
	public String  getHexDiff(String s1,String s2) {
		
		if(s1.length() > 8) {	
			s1 = s1.substring(s1.length() - 8);
		}
		Long n1 = Long.parseLong(s1,16);
		Long n2 = Long.parseLong(s2,16);
		return String.valueOf(n2 - n1);
		
	}
	
	public String parseFile(String filename,String indexPath) throws IOException {
		
		InputStream in = new FileInputStream(filename);
		BufferedReader bufferReader = new BufferedReader(new InputStreamReader(in),100000);
		String s1 = bufferReader.readLine(),s2;
		StringBuilder sb = new StringBuilder();
		while(bufferReader.ready()) {
			s2 = bufferReader.readLine();
			//s1 = s1.substring(0,s1.indexOf(" ")); 
			//s2 = s2.substring(0,s2.indexOf(" "));
			//mat = patt.matcher(s1);
			//if(s1.startsWith(".idata"))
				//System.out.println();
			if((s1.matches("^(.text\\d?:).*") || s1.matches("^(.i?data:).*") || s1.matches("^(seg\\d*:).*") || s1.matches("^(iuagwws:).*"))  
				&& ( s2.matches("^(.text\\d?:).*") || s2.matches("^(.i?data:).*") || s2.matches("^(seg\\d*:).*") || s2.matches("^(iuagwws:).*"))) {
			//if((s1.startsWith(".text") || s1.startsWith(".data")) && (s2.startsWith(".text") || s2.startsWith(".data"))) {
						s1 = s1.replaceAll(".text\\d?:", "").replaceAll(".i?data\\d?:", "").replaceAll("\\s+.*", "")
								.replaceAll("^(seg\\d*:)", "").replaceAll("^(iuagwws:)",""); 
						s2 = s2.replaceAll(".text\\d?:", "").replaceAll(".i?data\\d?:", "").replaceAll("\\s+.*", "")
								.replaceAll("^(seg\\d*:)", "").replaceAll("^(iuagwws:)", "");//.substring();
						if(!s1.equals(s2)) {
							sb.append(getHexDiff(s1,s2));
							sb.append(" ");
						}
			}	
			s1 = s2;
		}
		if(bufferReader != null)
			bufferReader.close();
		return sb.toString();
		//luceneIndex(sb.toString(),filename,indexPath);
	}

	//public void luceneIndex(String str,String filename,String indexDirectory) throws IOException{
	public void luceneIndex(Map<String,String> fileDataMap,String indexDirectory) throws IOException{
		Directory fsdir = FSDirectory.open(new File(indexDirectory));
		Analyzer analyzer = new BAnalyzer(4,4);
		IndexWriterConfig config = new IndexWriterConfig(Version.LUCENE_4_10_0,analyzer);
		config.setOpenMode(OpenMode.CREATE_OR_APPEND);
		IndexWriter writer = new IndexWriter(fsdir, config);
		Document doc;
		/*doc.add(new StringField("id",filename,Field.Store.YES));
		//doc.add(new TextField("data",str,Field.Store.YES));
		doc.add(new VecTextField("data",str,Field.Store.YES));
		writer.addDocument(doc);
		writer.close();*/
		List<Document> docs = new ArrayList<Document>();
		for(Entry<String,String> entry: fileDataMap.entrySet()){
			doc = new Document();
			doc.add(new StringField("id",entry.getKey(),Field.Store.YES));
			doc.add(new VecTextField("data",entry.getValue(),Field.Store.YES));
			docs.add(doc);
		}
		writer.addDocuments(docs);
		writer.close();
	}
	
	
	
	
	public void ReadLuceneIndex(int index,String indexDirectory,String fieldName) throws IOException{
		//String indexDirectory = "/media/jus-mine/New Volume/Kaggle/index" + String.valueOf(index) + "/";
		IndexReader reader = DirectoryReader.open(FSDirectory.open(new File(indexDirectory)));
		int NoOfDocs = reader.maxDoc();
		Terms terms;
		TermsEnum termsEnum = null;
		Document doc;
		List<String> tempString;
		List<String> retainedString = getTermsVector(reader, termsEnum, 0,fieldName);
		System.out.println(retainedString.size());
		for( int i = 1; i < reader.maxDoc(); i++ ) {
			tempString = getTermsVector(reader, termsEnum, i,fieldName);
			if(tempString != null ) {
				retainedString.retainAll(tempString);
				System.out.println(retainedString.size());
			}
		}
		System.out.println(retainedString.size());
		for(String str: retainedString)
			System.out.println(str);
	}

	private List<String> getTermsVector(IndexReader reader, TermsEnum termsEnum,int i,String fieldName) throws IOException {
		
		Terms terms; Document doc;
		List<String> tempString;
		doc = reader.document(i);
		terms = reader.getTermVector(i,fieldName);
		//reader.getTermVectors(arg0)
		System.out.println(reader.document(i).get("name") + " " + i);
		
		if(terms  == null){
			
			return null;
		}
		termsEnum = terms.iterator(termsEnum);
		tempString = new ArrayList<String>();
		while(termsEnum.next() != null){
			//System.out.println(termsEnum.term().toString());
			termsEnum.next();
			tempString.add(termsEnum.term().utf8ToString());
			
		}		
		return tempString;
	}
	
	public Map<String,Long> getAllUniqueTerms(int index,String indexDirectory,String fieldName) throws IOException{				
		//String indexDirectory = "/media/jus-mine/New Volume/Kaggle/index" + String.valueOf(index) + "/";
		IndexReader reader = DirectoryReader.open(FSDirectory.open(new File(indexDirectory)));
		Map<String,Boolean> instructionMap = new HashMap<String, Boolean>();
		makeMap(instructionMap);
		TermsEnum termsEnum = null; Terms terms;
		Map<String,Long> termFreq = new HashMap<String, Long>();
		String text;
		for(int i = 0; i < reader.maxDoc(); i++){
			terms = reader.getTermVector(i,fieldName);
			if(terms != null) {
				termsEnum = terms.iterator(null);
				while(termsEnum.next() != null) {
					text = termsEnum.term().utf8ToString().trim();
					if(instructionMap.containsKey(text)) {
						if(termFreq.containsKey(text)) 
							termFreq.put(text,termFreq.get(text) + termsEnum.totalTermFreq());
						else
							termFreq.put(text,termsEnum.totalTermFreq());
					}
				}
			}
		}
		return termFreq;
	}
	
	public List<String> getDataForLabels(int classLabel) throws SQLException {
		
		MysqlConnector mysql = new MysqlConnector();
		mysql.connect();
		List<String> filenames = mysql.getData(classLabel);
		return filenames;		
	}
	
	/*
public void ProcessClass(int classLabel) throws IOException {
	
		String indexPath = String.format("/u/ploya/index/index%d", classLabel);
		
		Map<String,Analyzer> perFieldAnalyzer = AddPerFieldAnalyser();
		
		String prefixPath = "/home/vbox/train/train/";
		HashMap<String,Integer> map = new HashMap<String, Integer>(); 
		getTrainlabels(map);
		Map<String,Boolean> instructionMap = new HashMap<String, Boolean>();
		makeMap(instructionMap);
		try {
			List<String> filenames = getDataForLabels(classLabel);
			int count  = 0;
			int totalCount = 0;
			StringBuilder ngramBuilder = new StringBuilder();
			StringBuilder opcodeBuilder = new StringBuilder();
			List<Document> docs = new ArrayList<Document>();
			Document doc;
			String compFileName = "";
			for(String str: filenames) {
				ngramBuilder.setLength(0);
				opcodeBuilder.setLength(0);
				System.out.println(String.format("File Number:%d and name:%s",count + totalCount,str));
				compFileName = String.format("%s%s",prefixPath,str);
				doc = new Document();
				//parseFile(compFileName,ngramBuilder,opcodeBuilder,instructionMap,doc);
				parseFile(compFileName,instructionMap,doc);
				doc.add(new TextField("name",str,Store.YES));
				doc.add(new VecTextField("ngramData",ngramBuilder.toString(),Store.YES));
				doc.add(new VecTextField("opcodeData",opcodeBuilder.toString(),Store.YES));
				docs.add(doc);
				count++; 
				if(count % 100 == 0) {
					writeToLucene(docs, indexPath);
					//writer.addDocuments(docs);
					docs.clear();
					totalCount+= count;
					count = 0;
				}
			}
			if(count > 0) {
				writeToLucene(docs, indexPath);
				docs.clear();
			}
				
		} catch (SQLException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		} catch (IOException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}
	}*/


	public void ProcessClass(int classLabel,String indexPath) throws IOException {
		
		
		
		ExecutorService executor = Executors.newFixedThreadPool(20);

		//String indexPath = String.format("/u/ploya/index/index%d", classLabel);
		Map<String,Analyzer> perFieldAnalyzer = AddPerFieldAnalyser();
		PerFieldAnalyzerWrapper wrapper = new PerFieldAnalyzerWrapper(new StandardAnalyzer(),perFieldAnalyzer);
		
		
		
		RAMDirectory ramDir = new RAMDirectory();
		IndexWriterConfig config = new IndexWriterConfig(Version.LUCENE_4_10_0,wrapper);
		config.setOpenMode(OpenMode.CREATE_OR_APPEND);
		IndexWriter writer = new IndexWriter(ramDir,config);
		String prefixPath = "/home/vbox/train/";
		HashMap<String,Integer> map = new HashMap<String, Integer>(); 
		Map<String,Boolean> instructionMap = new HashMap<String, Boolean>();
		makeMap(instructionMap);
		
		
		List<Document> docs = new ArrayList<Document>();
		try {
				List<String> filenames = getDataForLabels(classLabel);
				int totalCount = 0;
				String compFileName = "";
				for(String str: filenames) {
				//	System.out.println(String.format("File Number:%d and name:%s",count + totalCount,str));
					compFileName = String.format("%s%s",prefixPath,str);
					Runnable worker = new ParallerParse(compFileName,instructionMap,writer);
				//	Runnable worker = new ParallerParse(compFileName,instructionMap,docs);
		            executor.execute(worker);
					//parseFile(compFileName,instructionMap,writer);
				}
				
		} catch (SQLException e) {
			e.printStackTrace();
		} finally {
			//writer.close();
			executor.shutdown();
		}
		
		
        while (!executor.isTerminated()) { }
        //writeToLucene(docs, indexPath);
        
        writer.close();
        
        File indexFileDir = new File(indexPath);
        Directory fsdir = FSDirectory.open(new File(indexPath));
		for(String file:ramDir.listAll()){
        	ramDir.copy(fsdir, file,file,IOContext.DEFAULT);
        }
        
	}
	
	public void writeToLucene(List<Document> docs, String indexPath) throws IOException{
		
		Map<String,Analyzer> perFieldAnalyzer = AddPerFieldAnalyser();
		PerFieldAnalyzerWrapper wrapper = new PerFieldAnalyzerWrapper(new StandardAnalyzer(),perFieldAnalyzer);
		Directory fsdir = FSDirectory.open(new File(indexPath));
		IndexWriterConfig config = new IndexWriterConfig(Version.LUCENE_4_10_0,wrapper);
		config.setOpenMode(OpenMode.CREATE_OR_APPEND);
		IndexWriter writer = new IndexWriter(fsdir,config);
		writer.addDocuments(docs);
		writer.close();
	}
	
	public static void main(String[] args) throws IOException, ParseException {
		
		//String fieldName = "ngramData";
		String fieldName = "opcodeData";
		PreProDifferenceASM pre = new PreProDifferenceASM();
		
		
		//for(int i = 4; i < 10; i++){
		
			int classLabel = Integer.parseInt(args[0]);
			String indexPath = String.format("/u/ploya/kaggle_train_index/index%d/", classLabel);
			pre.ProcessClass(classLabel,indexPath);
			//pre.ReadLuceneIndex(classLabel,indexPath,fieldName);
			//Map<String,Long> dict = pre.getAllUniqueTerms(classLabel,indexPath,fieldName);
			//pre.writeFreqToFile(dict,classLabel);
		//}
		
		
		//String indexPath = String.format("/media/jus-mine/New Volume/Kaggle/index%d/", classLabel);
		//pre.updateDocument(indexPath,"5yl20B1IoetGVjsQFwP8");
		
	}

	private void writeFreqToFile(Map<String, Long> dict,int classLabel) throws IOException {
		StringBuilder strBuilder = new StringBuilder();
		for(Entry<String,Long> entry : dict.entrySet() ) {
			 strBuilder.append(entry.getKey() + "," + entry.getValue());
			 strBuilder.append("\n");
			 
		 }
		 String path  = String.format("/u/ploya/kaggle_outputs/index%d/opcode.csv", classLabel);
		 FileManager.writeToFile(strBuilder.toString(),path);
	}
	
	/*void updateDocument(String indexPath,String filename) throws IOException, ParseException{
		
		Directory fsdir = FSDirectory.open(new File(indexPath));
		IndexReader reader = IndexReader.open(fsdir);
		Analyzer analyzer = new KeywordAnalyzer();
		IndexSearcher searcher = new IndexSearcher(reader);
		QueryParser parser = new QueryParser("id",analyzer);
		Query query = parser.parse(filename);
		TopDocs topdocs = searcher.search(query, 100);
		reader.close();
		System.out.println(topdocs.totalHits);
		IndexWriterConfig config = new IndexWriterConfig(Version.LUCENE_4_10_0,analyzer);
		config.setOpenMode(OpenMode.CREATE_OR_APPEND);
		IndexWriter indexWriter = new IndexWriter(fsdir, config);
		indexWriter.deleteDocuments(query);
		indexWriter.close();
	}*/
	
	
	
	
	//public void parseFile(String filename,StringBuilder sbNgram,StringBuilder wholeLine,Map<String,Boolean> instructionMap,Document doc) throws IOException{
	public void parseFile(String filename,Map<String,Boolean> instructionMap,Document doc) throws IOException{
	StringBuilder sbNgram = new StringBuilder();StringBuilder wholeLine = new StringBuilder();
		String line;String[] temp;
		InputStream in = new FileInputStream(filename+".asm");
		BufferedReader bufferReader = new BufferedReader(new InputStreamReader(in),100000);
		String s1,s2="";
		s1 = bufferReader.readLine(); 
		String opcodeStr;
		Pattern pattern = Pattern.compile("^.*:([A-F0-9]*)\\s+.*");
		Matcher mat;
		mat = pattern.matcher(s1);
		if(mat.matches()) 
			s1 = mat.group(1).trim();
		while((line = bufferReader.readLine()) !=  null) {
			if(line.startsWith("HEADER")) continue;
			if(line.indexOf(";") > -1)
				line = line.substring(0,line.indexOf(";"));
			mat = pattern.matcher(line);
			if(mat.matches()) {
				s2 = mat.group(1).trim();
				if(!s1.equals(s2) && s1.length() > 0 && s2.length() > 0) {
					sbNgram.append(getHexDiff(s1,s2));
					sbNgram.append(" ");
				}
			}
			s1 = s2;
			line = line.replaceAll("[A-F0-9]*", "");
			temp = splitWithNonEmptyEntries(line, "\t");
			if(temp.length > 1) {
				opcodeStr = temp[1].trim();
				temp = opcodeStr.split("\\s+");
				for(String str: temp){
					opcodeStr = str.trim();
					if(instructionMap.containsKey(opcodeStr)){
						wholeLine.append(opcodeStr);
						wholeLine.append(" ");
						break;
					}
				}
			}
		}
		bufferReader.close();
		doc.add(new TextField("name",filename,Store.YES));
		doc.add(new VecTextField("ngramData",sbNgram.toString(),Store.YES));
		doc.add(new VecTextField("opcodeData",wholeLine.toString(),Store.YES));
	}
	
	public Map<String,Analyzer> AddPerFieldAnalyser() {
		
		Map<String,Analyzer> analyzerPerField = new HashMap<>();
		analyzerPerField.put("name", new KeywordAnalyzer());
		analyzerPerField.put("ngramData", new BAnalyzer(4,4));
		analyzerPerField.put("opcodeData", new BAnalyzer(4,4));
		return analyzerPerField;
	}
	
	public String[] splitWithNonEmptyEntries(String input,String delim){
		
		List<String> list = new ArrayList<String>(); 
		String temp[] = input.split(delim);
		for(String str: temp){
			if(str.trim().length() > 0){
				list.add(str);
			}
		}
		return list.toArray(new String[list.size()]);
	}
	
}
